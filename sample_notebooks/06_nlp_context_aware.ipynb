{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "BiKR78k2k-xF",
   "metadata": {
    "id": "BiKR78k2k-xF"
   },
   "source": [
    "# Natural Language Processing: Context-aware Tasks\n",
    "\n",
    "Hi everyone! Today, we're continuing with NLP, specifically looking at context-aware problems, features that we can extract at a document-level, and common context-aware tasks such as rules-based sentiment analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jAyu5SR9k-xG",
   "metadata": {
    "id": "jAyu5SR9k-xG"
   },
   "source": [
    "We will be extensively using SpaCy's `en_core_web_lg model` for many of the context-aware tasks today. This model was pre-trained on several corpuses such as OntoNotes 5, GloVe Common Crawl, and others ([source](https://spacy.io/models/en])). It comes with pipeline components such as a tokenizer, a POS tagger, a dependency parse, a lemmatizer, and an named entity recognizer. It also comes with pre-trained document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ERp2NAZzk-xG",
   "metadata": {
    "id": "ERp2NAZzk-xG"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spacy_pipeline.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d9d8dbb0e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spacy_pipeline.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1225\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spacy_pipeline.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='spacy_pipeline.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-m0QOaJXk-xH",
   "metadata": {
    "id": "-m0QOaJXk-xH"
   },
   "source": [
    "By default, the SpaCy pipeline's preprocessing steps include tokenization, POS tagging, dependency parsing, and named entity recognition only. However, users have the option to use the other features such as lemmatization, embedding, and other self-defined steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dNLyvwxk-xH",
   "metadata": {
    "id": "4dNLyvwxk-xH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (3.1.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: setuptools in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (47.1.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (8.0.10)\n",
      "Requirement already satisfied: jinja2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en-core-web-lg==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0-py3-none-any.whl (777.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 777.1 MB 41 kB/s  eta 0:00:013     |█████▊                          | 138.7 MB 10.8 MB/s eta 0:01:00     |███████████████▊                | 381.8 MB 8.7 MB/s eta 0:00:46     |███████████████████████▎        | 564.0 MB 7.3 MB/s eta 0:00:30     |██████████████████████████▍     | 640.3 MB 14.7 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from en-core-web-lg==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (47.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.7.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<3,>=2.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run only if you do not have SpaCy and the en_core_web_lg model installed on your device yet\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "international-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1ae7bf100>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxGLeCyxk-xH",
   "metadata": {
    "id": "sxGLeCyxk-xH"
   },
   "source": [
    "### Parts-of-speech (POS) tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zMsfimrOk-xH",
   "metadata": {
    "id": "zMsfimrOk-xH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BmAq17V-k-xI",
   "metadata": {
    "id": "BmAq17V-k-xI"
   },
   "outputs": [],
   "source": [
    "# Import spacy and the en_core_web_lg model\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "except:\n",
    "    print(\"Error loading 'en_core_web_lg' model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "r0HPjvHgk-xI",
   "metadata": {
    "id": "r0HPjvHgk-xI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the en_core_web_lg_model to pre-process our text\n",
    "SpaCy's pre-trained model automatically determines various linguistic properties\n",
    "such as POS tags and dependency trees\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(\"The Philippine flight was delayed due to trouble with the airplane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "HyIvDdZqk-xI",
   "metadata": {
    "id": "HyIvDdZqk-xI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alphabet</th>\n",
       "      <th>is_stopword</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Philippine</td>\n",
       "      <td>philippine</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>delayed</td>\n",
       "      <td>delay</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>due</td>\n",
       "      <td>due</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>due</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trouble</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>airplane</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text       lemma    pos  tag dependency  shape is_alphabet  \\\n",
       "0          The         the    DET   DT        det    Xxx        True   \n",
       "1   Philippine  philippine    ADJ   JJ       amod  Xxxxx        True   \n",
       "2       flight      flight   NOUN   NN  nsubjpass   xxxx        True   \n",
       "3          was          be    AUX  VBD    auxpass    xxx        True   \n",
       "4      delayed       delay   VERB  VBN       ROOT   xxxx        True   \n",
       "5          due         due    ADP   IN       prep    xxx        True   \n",
       "6           to          to    ADP   IN      pcomp     xx        True   \n",
       "7      trouble     trouble   NOUN   NN       pobj   xxxx        True   \n",
       "8         with        with    ADP   IN       prep   xxxx        True   \n",
       "9          the         the    DET   DT        det    xxx        True   \n",
       "10    airplane    airplane   NOUN   NN       pobj   xxxx        True   \n",
       "11           .           .  PUNCT    .      punct      .       False   \n",
       "\n",
       "   is_stopword head_text head_pos  \n",
       "0         True    flight     NOUN  \n",
       "1        False    flight     NOUN  \n",
       "2        False   delayed     VERB  \n",
       "3         True   delayed     VERB  \n",
       "4        False   delayed     VERB  \n",
       "5         True   delayed     VERB  \n",
       "6         True       due      ADP  \n",
       "7        False        to      ADP  \n",
       "8         True   trouble     NOUN  \n",
       "9         True  airplane     NOUN  \n",
       "10       False      with      ADP  \n",
       "11       False   delayed     VERB  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize every \"token\" in the document\n",
    "tokens = pd.DataFrame(columns=\n",
    "                      ['text', 'lemma', 'pos', 'tag',\n",
    "                       'dependency', 'shape', 'is_alphabet',\n",
    "                       'is_stopword', 'head_text', 'head_pos'])\n",
    "\n",
    "for token in doc:\n",
    "    data = [token.text, token.lemma_, token.pos_,\n",
    "            token.tag_, token.dep_, token.shape_,\n",
    "            token.is_alpha, token.is_stop,\n",
    "            token.head.text, token.head.pos_]\n",
    "    tokens.loc[len(tokens)] = data\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6LEWLj9rk-xI",
   "metadata": {
    "id": "6LEWLj9rk-xI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e21512eae990413e9d05d38477e051ee-0\" class=\"displacy\" width=\"1975\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Philippine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">flight</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">delayed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">due</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">trouble</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">airplane.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-6\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,179.0 L1278.0,167.0 1262.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-7\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,179.0 L1453.0,167.0 1437.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-8\" stroke-width=\"2px\" d=\"M1645,177.0 C1645,89.5 1795.0,89.5 1795.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,179.0 L1637,167.0 1653,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e21512eae990413e9d05d38477e051ee-0-9\" stroke-width=\"2px\" d=\"M1470,177.0 C1470,2.0 1800.0,2.0 1800.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e21512eae990413e9d05d38477e051ee-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,179.0 L1808.0,167.0 1792.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_bL36cIGk-xI",
   "metadata": {
    "id": "_bL36cIGk-xI"
   },
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "XG0ZpwCPk-xJ",
   "metadata": {
    "id": "XG0ZpwCPk-xJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the en_core_web_lg_model to pre-process our text\n",
    "SpaCy's pre-trained model also determines any named entities from text. \n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(\"The Philippine flight was delayed yesterday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "IP_JeOCdk-xJ",
   "metadata": {
    "id": "IP_JeOCdk-xJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Philippine, yesterday)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ktcZKj1k-xJ",
   "metadata": {
    "id": "3ktcZKj1k-xJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philippine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " flight was delayed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WIY8arb1k-xJ",
   "metadata": {
    "id": "WIY8arb1k-xJ"
   },
   "source": [
    "### Rules-based sentiment analysis\n",
    "\n",
    "For sentiment analysis, we will be using the VADER model ([source](https://github.com/cjhutto/vaderSentiment)). VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. \n",
    "\n",
    "We will modify the SpaCy pipeline to add the additional step of using the VADER model to calculate the sentiment polarity of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "J30hyqNFk-xK",
   "metadata": {
    "id": "J30hyqNFk-xK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 374 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (4.0.0)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment and run only if you do not have VADER installed on your device yet\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cM0QeQHek-xK",
   "metadata": {
    "id": "cM0QeQHek-xK"
   },
   "outputs": [],
   "source": [
    "# Import VADER model\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Import Doc for extending the SpaCy pipeline\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "zLR_kKaLk-xK",
   "metadata": {
    "id": "zLR_kKaLk-xK"
   },
   "outputs": [],
   "source": [
    "# Define sentiment analysis extensions\n",
    "\"\"\"\n",
    "You can define the extension as a regular Python function:\n",
    "def sentiment_analysis(doc):\n",
    "    return sia.polarity_scores(doc.text)\n",
    "\"\"\"\n",
    "# Or you can create an anonymous lambda functions\n",
    "sentiment_analysis = lambda doc: sia.polarity_scores(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hb42zhi2k-xK",
   "metadata": {
    "id": "hb42zhi2k-xK"
   },
   "outputs": [],
   "source": [
    "# Instantiate NLP pipeline and set extensions\n",
    "nlp_with_sentiment = spacy.load(\"en_core_web_lg\")\n",
    "Doc.set_extension(\"sentiment\", getter=sentiment_analysis, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wL8_UDrxk-xK",
   "metadata": {
    "id": "wL8_UDrxk-xK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.708, 'pos': 0.292, 'compound': 0.4389}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp_with_sentiment(\"I love this school, but it's tiring sometimes!\")\n",
    "doc._.sentiment # Acccess custom properties using the \"._.\" operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JBKM44Aqk-xK",
   "metadata": {
    "id": "JBKM44Aqk-xK"
   },
   "source": [
    "### Process multiple documents\n",
    "\n",
    "SpaCy pipelines have an optimazation for processing multiple texts all at once using the `nlp.pipe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "jlwp4XCRk-xK",
   "metadata": {
    "id": "jlwp4XCRk-xK"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"I love this school, but it's tiring sometimes!\",\n",
    "        \"I'm looking forward to Christmas break.\",\n",
    "        \"I'm sad that midterms are over.\",\n",
    "        \"School is almost over.\",\n",
    "        \"I'll be relaxing during the Christmas break.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minimal-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text\n",
       "0  I love this school, but it's tiring sometimes!\n",
       "1         I'm looking forward to Christmas break.\n",
       "2                 I'm sad that midterms are over.\n",
       "3                          School is almost over.\n",
       "4    I'll be relaxing during the Christmas break."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "GiL-lN4lk-xL",
   "metadata": {
    "id": "GiL-lN4lk-xL"
   },
   "outputs": [],
   "source": [
    "# Use the nlp.pipe() method to process a collection of texts\n",
    "docs = nlp_with_sentiment.pipe(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "Opro5uXUk-xL",
   "metadata": {
    "id": "Opro5uXUk-xL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>com_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "      <td>(I, love, this, school, ,, but, it, 's, tiring...</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "      <td>(I, 'm, looking, forward, to, Christmas, break...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "      <td>(I, 'm, sad, that, midterms, are, over, .)</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "      <td>(School, is, almost, over, .)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "      <td>(I, 'll, be, relaxing, during, the, Christmas,...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  \\\n",
       "0  I love this school, but it's tiring sometimes!   \n",
       "1         I'm looking forward to Christmas break.   \n",
       "2                 I'm sad that midterms are over.   \n",
       "3                          School is almost over.   \n",
       "4    I'll be relaxing during the Christmas break.   \n",
       "\n",
       "                                            document  com_sent  pos_sent  \\\n",
       "0  (I, love, this, school, ,, but, it, 's, tiring...    0.4389     0.292   \n",
       "1  (I, 'm, looking, forward, to, Christmas, break...    0.0000     0.000   \n",
       "2         (I, 'm, sad, that, midterms, are, over, .)   -0.4767     0.000   \n",
       "3                      (School, is, almost, over, .)    0.0000     0.000   \n",
       "4  (I, 'll, be, relaxing, during, the, Christmas,...    0.4939     0.348   \n",
       "\n",
       "   neg_sent  neu_sent  \n",
       "0     0.000     0.708  \n",
       "1     0.000     1.000  \n",
       "2     0.383     0.617  \n",
       "3     0.000     1.000  \n",
       "4     0.000     0.652  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modified = pd.DataFrame(columns=['text', 'document', 'com_sent', 'pos_sent', 'neg_sent', 'neu_sent'])\n",
    "for doc in docs:\n",
    "    df_modified = df_modified.append(\n",
    "        {\n",
    "            'text': doc.text,\n",
    "            'document': doc,\n",
    "            'com_sent': doc._.sentiment['compound'],\n",
    "            'pos_sent': doc._.sentiment['pos'],\n",
    "            'neg_sent': doc._.sentiment['neg'],\n",
    "            'neu_sent': doc._.sentiment['neu']\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "df_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Er9ZOz9Mk-xL",
   "metadata": {
    "id": "Er9ZOz9Mk-xL"
   },
   "source": [
    "### Document embeddings\n",
    "\n",
    "SpaCy's `en_core_web_lg` model also comes with pre-trained document embeddings. As such, we can simply use them to immediately retrieve the embeddings of our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "p6H0YZ5vk-xL",
   "metadata": {
    "id": "p6H0YZ5vk-xL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I'll be relaxing during the Christmas break."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vlRud-2Xk-xL",
   "metadata": {
    "id": "vlRud-2Xk-xL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector.shape # The embedding uses 300 feature columns only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "qbCv9PK9k-xL",
   "metadata": {
    "id": "qbCv9PK9k-xL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.69008091e-01,  2.25695238e-01, -1.68768674e-01, -1.36101559e-01,\n",
       "        9.52071026e-02, -1.27706647e-01,  6.65480122e-02, -7.65754357e-02,\n",
       "        4.17082235e-02,  2.11479855e+00, -3.06387693e-01,  1.54878963e-02,\n",
       "        1.47993699e-01, -7.26084504e-03,  9.56096649e-02, -1.20751448e-01,\n",
       "       -9.59463567e-02,  1.24279106e+00, -1.21257037e-01,  3.46791223e-02,\n",
       "       -2.60731522e-02,  1.58247799e-02, -9.91496742e-02, -1.62487905e-02,\n",
       "       -1.03149183e-01,  9.22244191e-02, -1.16027325e-01, -1.52984649e-01,\n",
       "       -5.60563465e-04, -3.21794413e-02, -1.47145286e-01, -2.52799004e-01,\n",
       "       -1.57193437e-01,  1.14202991e-01,  1.21319994e-01, -8.64599831e-03,\n",
       "        2.11264670e-01,  4.57501560e-02, -1.73189901e-02, -4.68007624e-02,\n",
       "       -5.22216633e-02,  2.49998440e-04, -3.89611162e-02,  2.48558004e-04,\n",
       "       -2.88100052e-03,  1.76195100e-01, -1.56749442e-01, -1.43664241e-01,\n",
       "       -4.12045531e-02,  4.65430021e-02, -4.52112257e-02, -1.05004005e-01,\n",
       "        1.81275219e-01, -2.92663667e-02,  6.02491163e-02, -4.52881120e-02,\n",
       "        1.35383354e-02, -1.25303447e-01,  3.50456797e-02, -3.18884850e-05,\n",
       "       -8.48876536e-02, -2.11524144e-02,  6.89355517e-03,  2.15680778e-01,\n",
       "       -3.81040014e-02, -4.88584787e-02, -4.37708907e-02,  1.89573556e-01,\n",
       "       -3.40836914e-03,  1.16790667e-01,  1.27909780e-01,  7.56918490e-02,\n",
       "        1.89975560e-01, -8.01728889e-02,  2.73830861e-01,  4.74545583e-02,\n",
       "        3.78357433e-02,  8.01730007e-02, -2.26582870e-01,  6.78760111e-02,\n",
       "        1.30298331e-01,  1.97376549e-01, -2.01991230e-01,  7.27420524e-02,\n",
       "       -1.12283893e-01, -9.74534974e-02,  1.43515006e-01, -4.22462150e-02,\n",
       "        3.11261326e-01,  1.13580331e-01,  4.69759516e-02,  1.06914736e-01,\n",
       "       -2.52913330e-02,  1.06564775e-01,  7.90063366e-02,  1.75771154e-02,\n",
       "        1.87115595e-02, -1.17481999e-01,  5.83332926e-02, -1.79405510e-02,\n",
       "       -2.47072261e-02,  3.60056646e-02, -5.57320043e-02, -5.64332269e-02,\n",
       "        1.66180670e-01, -6.55314445e-01,  3.82308871e-01, -1.04069740e-01,\n",
       "        5.62283322e-02, -1.37385666e-01,  1.21720448e-01, -2.44869784e-01,\n",
       "        7.66339973e-02, -9.39946696e-02,  8.91013369e-02, -1.76565200e-01,\n",
       "        4.71347757e-02,  1.21207662e-01, -2.13664889e-01, -4.41889279e-03,\n",
       "        1.42457888e-01, -6.71111122e-02, -4.15758826e-02,  1.19366921e-01,\n",
       "       -5.52699938e-02,  1.57718718e-01, -6.33840039e-02, -1.43905893e-01,\n",
       "        1.51640236e-01,  8.32019448e-02,  7.85555542e-02, -1.64706126e-01,\n",
       "       -2.09939003e-01,  1.16106883e-01,  2.37812549e-01,  8.41883346e-02,\n",
       "        1.45315463e-02,  5.26115634e-02,  5.50720433e-04, -9.59177837e-02,\n",
       "       -1.79633224e+00,  1.17103897e-01,  6.90722167e-02, -1.07685141e-01,\n",
       "        3.36099509e-03,  3.92047763e-02, -1.22179113e-01,  9.26374421e-02,\n",
       "        5.36766686e-02, -2.19308779e-01, -1.18846007e-01,  1.10863447e-01,\n",
       "       -1.04024429e-02,  7.13724345e-02, -1.12965889e-01, -5.30984811e-02,\n",
       "        1.91596672e-01,  1.20359659e-01, -4.21894416e-02, -2.78807785e-02,\n",
       "        3.62110976e-03, -2.80411914e-03, -1.31371796e-01, -6.27325550e-02,\n",
       "       -2.71147564e-02, -2.05195889e-01,  7.33704343e-02,  7.50346631e-02,\n",
       "        1.51713565e-01,  6.55411184e-02,  1.54237226e-01,  6.65095672e-02,\n",
       "       -3.83941084e-02, -9.41737741e-02, -1.03768036e-01, -5.67220966e-04,\n",
       "       -7.58896768e-02, -1.03943191e-01,  4.88177268e-03, -2.61134574e-05,\n",
       "       -1.50450855e-01, -1.68208659e-01, -8.35569724e-02,  9.23730135e-02,\n",
       "        7.98831210e-02, -1.54944673e-01, -1.11017443e-01,  1.46655552e-02,\n",
       "        2.30446130e-01, -1.44897802e-02, -2.76193395e-02, -2.28465535e-02,\n",
       "       -1.25145003e-01, -8.86883363e-02,  1.93637133e-01,  2.36230105e-01,\n",
       "        9.74034369e-02, -2.53785670e-01,  6.87700324e-03,  8.65442231e-02,\n",
       "       -9.04887840e-02, -5.63942194e-02,  1.24644317e-01,  3.53402197e-02,\n",
       "        2.46256769e-01, -7.23222224e-03, -1.01644383e-03,  8.34902301e-02,\n",
       "        9.65888947e-02, -4.79429550e-02, -1.70974508e-02,  1.42045557e-01,\n",
       "        2.04871129e-02, -1.83792442e-01, -2.03133631e-03,  1.58189714e-01,\n",
       "        1.31369442e-01, -8.16858858e-02, -1.85324982e-01,  2.18765900e-01,\n",
       "        1.15416460e-01, -9.13327634e-02, -4.66597825e-02,  6.77546635e-02,\n",
       "       -1.86069787e-01, -1.04684919e-01,  6.01500012e-02,  6.86603338e-02,\n",
       "       -1.05659999e-02, -4.32779975e-02, -1.15628885e-02, -2.03222688e-03,\n",
       "        1.63271010e-01,  1.46250010e-01, -1.07807338e-01, -8.68904516e-02,\n",
       "        2.55244481e-03, -2.14569345e-01, -2.27484122e-01,  9.83738899e-02,\n",
       "       -7.91111961e-03, -1.07323110e-01,  3.56113389e-02,  2.28172883e-01,\n",
       "       -4.36599739e-03, -4.86177802e-02, -1.31758437e-01,  3.34117748e-02,\n",
       "       -1.85134679e-01,  5.17566726e-02, -9.39297304e-03, -7.63822198e-02,\n",
       "       -6.85185492e-02,  1.06907766e-02,  1.17562450e-01,  3.21038872e-01,\n",
       "        1.46711662e-01, -1.84286669e-01, -8.36474001e-02, -1.94414426e-02,\n",
       "        9.62742195e-02,  1.68721989e-01,  7.05020577e-02,  3.92924435e-02,\n",
       "        1.32032573e-01, -1.10389881e-01, -1.07983887e-01,  1.58529639e-01,\n",
       "        1.73337772e-01,  4.12225574e-02, -9.84863192e-02, -1.33460224e-01,\n",
       "       -1.55995578e-01,  1.05621116e-02, -8.02761316e-03,  2.19163328e-01,\n",
       "       -9.81157646e-02,  6.78752214e-02,  7.98539296e-02,  2.91324466e-01,\n",
       "        3.26016694e-01, -2.12641001e-01, -1.26933768e-01, -5.79854436e-02,\n",
       "        7.51078129e-02,  1.48822553e-03,  1.57899320e-01, -1.09769881e-01,\n",
       "        2.61167347e-01,  1.04090564e-01, -4.04110551e-03,  1.21574983e-01,\n",
       "       -9.74602252e-02, -1.45725340e-01,  1.23401433e-01,  4.19881158e-02,\n",
       "        5.87355569e-02,  9.44890082e-02, -8.09593424e-02,  1.35943115e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector # This is the embedding vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dk5tX8sAk-xM",
   "metadata": {
    "id": "dk5tX8sAk-xM"
   },
   "source": [
    "In the next following cells, we will attempt to embed a bunch of documents to retrieve their embedding vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "NUW2g0dEk-xM",
   "metadata": {
    "id": "NUW2g0dEk-xM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text\n",
       "0  I love this school, but it's tiring sometimes!\n",
       "1         I'm looking forward to Christmas break.\n",
       "2                 I'm sad that midterms are over.\n",
       "3                          School is almost over.\n",
       "4    I'll be relaxing during the Christmas break."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedded = df.copy()\n",
    "df_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "-cNhv_ovk-xM",
   "metadata": {
    "id": "-cNhv_ovk-xM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "      <td>(I, love, this, school, ,, but, it, 's, tiring...</td>\n",
       "      <td>-0.034511</td>\n",
       "      <td>0.327626</td>\n",
       "      <td>-0.127263</td>\n",
       "      <td>-0.147311</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>0.082281</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>-0.219449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>-0.049010</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>-0.047019</td>\n",
       "      <td>0.168925</td>\n",
       "      <td>-0.035583</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>-0.091751</td>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.060225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "      <td>(I, 'm, looking, forward, to, Christmas, break...</td>\n",
       "      <td>0.150931</td>\n",
       "      <td>0.201293</td>\n",
       "      <td>-0.315190</td>\n",
       "      <td>-0.080541</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.066926</td>\n",
       "      <td>0.099092</td>\n",
       "      <td>-0.045008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041712</td>\n",
       "      <td>0.092986</td>\n",
       "      <td>-0.039350</td>\n",
       "      <td>-0.083476</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>-0.062269</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.063932</td>\n",
       "      <td>-0.061941</td>\n",
       "      <td>0.207759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "      <td>(I, 'm, sad, that, midterms, are, over, .)</td>\n",
       "      <td>-0.054281</td>\n",
       "      <td>0.193412</td>\n",
       "      <td>-0.161498</td>\n",
       "      <td>-0.119088</td>\n",
       "      <td>-0.029463</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>-0.030172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069403</td>\n",
       "      <td>-0.009032</td>\n",
       "      <td>-0.021050</td>\n",
       "      <td>-0.123020</td>\n",
       "      <td>0.130481</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.027997</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.024441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "      <td>(School, is, almost, over, .)</td>\n",
       "      <td>-0.072062</td>\n",
       "      <td>0.285760</td>\n",
       "      <td>-0.049852</td>\n",
       "      <td>-0.164506</td>\n",
       "      <td>0.226770</td>\n",
       "      <td>-0.099472</td>\n",
       "      <td>-0.122914</td>\n",
       "      <td>-0.032732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>-0.105848</td>\n",
       "      <td>0.118661</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>-0.077340</td>\n",
       "      <td>0.092603</td>\n",
       "      <td>-0.024908</td>\n",
       "      <td>-0.121334</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.036161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "      <td>(I, 'll, be, relaxing, during, the, Christmas,...</td>\n",
       "      <td>0.169008</td>\n",
       "      <td>0.225695</td>\n",
       "      <td>-0.168769</td>\n",
       "      <td>-0.136102</td>\n",
       "      <td>0.095207</td>\n",
       "      <td>-0.127707</td>\n",
       "      <td>0.066548</td>\n",
       "      <td>-0.076575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004041</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>-0.097460</td>\n",
       "      <td>-0.145725</td>\n",
       "      <td>0.123401</td>\n",
       "      <td>0.041988</td>\n",
       "      <td>0.058736</td>\n",
       "      <td>0.094489</td>\n",
       "      <td>-0.080959</td>\n",
       "      <td>0.135943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  \\\n",
       "0  I love this school, but it's tiring sometimes!   \n",
       "1         I'm looking forward to Christmas break.   \n",
       "2                 I'm sad that midterms are over.   \n",
       "3                          School is almost over.   \n",
       "4    I'll be relaxing during the Christmas break.   \n",
       "\n",
       "                                            document         0         1  \\\n",
       "0  (I, love, this, school, ,, but, it, 's, tiring... -0.034511  0.327626   \n",
       "1  (I, 'm, looking, forward, to, Christmas, break...  0.150931  0.201293   \n",
       "2         (I, 'm, sad, that, midterms, are, over, .) -0.054281  0.193412   \n",
       "3                      (School, is, almost, over, .) -0.072062  0.285760   \n",
       "4  (I, 'll, be, relaxing, during, the, Christmas,...  0.169008  0.225695   \n",
       "\n",
       "          2         3         4         5         6         7  ...       290  \\\n",
       "0 -0.127263 -0.147311  0.046244  0.082281  0.057372 -0.219449  ... -0.036997   \n",
       "1 -0.315190 -0.080541  0.298213 -0.066926  0.099092 -0.045008  ... -0.041712   \n",
       "2 -0.161498 -0.119088 -0.029463  0.012523  0.049262 -0.030172  ... -0.069403   \n",
       "3 -0.049852 -0.164506  0.226770 -0.099472 -0.122914 -0.032732  ...  0.014001   \n",
       "4 -0.168769 -0.136102  0.095207 -0.127707  0.066548 -0.076575  ... -0.004041   \n",
       "\n",
       "        291       292       293       294       295       296       297  \\\n",
       "0 -0.049010 -0.035962 -0.047019  0.168925 -0.035583  0.019455 -0.091751   \n",
       "1  0.092986 -0.039350 -0.083476  0.057845 -0.062269 -0.000087  0.063932   \n",
       "2 -0.009032 -0.021050 -0.123020  0.130481  0.057626  0.000031 -0.027997   \n",
       "3 -0.105848  0.118661  0.025903 -0.077340  0.092603 -0.024908 -0.121334   \n",
       "4  0.121575 -0.097460 -0.145725  0.123401  0.041988  0.058736  0.094489   \n",
       "\n",
       "        298       299  \n",
       "0  0.053876  0.060225  \n",
       "1 -0.061941  0.207759  \n",
       "2 -0.001042 -0.024441  \n",
       "3  0.022020 -0.036161  \n",
       "4 -0.080959  0.135943  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed a bunch of documents and append them to a dataframe\n",
    "documents = []\n",
    "vectors = []\n",
    "\n",
    "for doc in nlp.pipe(df['text']):\n",
    "    documents.append(doc)\n",
    "    vectors.append(doc.vector)\n",
    "    \n",
    "df_embedded['document'] = pd.Series(documents, name='document')\n",
    "df_embedded = df_embedded.join(pd.DataFrame(vectors))\n",
    "df_embedded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NO7G81Ark-xM",
   "metadata": {
    "id": "NO7G81Ark-xM"
   },
   "source": [
    "### Document similarity\n",
    "\n",
    "Now that we have document embeddings, we can use techniques such as cosine similarity to determine similarity between texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "XX-yHDiJk-xM",
   "metadata": {
    "id": "XX-yHDiJk-xM"
   },
   "outputs": [],
   "source": [
    "a = nlp(\"Hello there!\")\n",
    "b = nlp(\"Greetings to you!\")\n",
    "c = nlp(\"Wikipedia is not a dictionary, or a usage or jargon guide.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lRvv3XvHk-xM",
   "metadata": {
    "id": "lRvv3XvHk-xM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158018311870442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.similarity(b) # The two sentences look very similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lGnxTlH0k-xN",
   "metadata": {
    "id": "lGnxTlH0k-xN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5575620500314596"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.similarity(c) # Not so similar (almost 50-50 coin toss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TSsCbYQdk-xN",
   "metadata": {
    "id": "TSsCbYQdk-xN"
   },
   "source": [
    "### Topic modeling and thematic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8GkeeE7Yk-xN",
   "metadata": {
    "id": "8GkeeE7Yk-xN"
   },
   "source": [
    "For topic modeling and thematic analysis, we will be using GenSim ([source](https://radimrehurek.com/gensim/)) and pyLDAvis ([source](https://github.com/bmabey/pyLDAvis)). We will use GenSim to implement the Latent-Dirichlet Allocation (LDA) model, and use pyLDAvis to visualize the results. \n",
    "\n",
    "WARNING: Your notebook might become buggy when using pyLDAvis. Once you are done looking at the visual, simply clear the output of the cell that uses the pyLDAvis chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "pO1f8H77k-xN",
   "metadata": {
    "id": "pO1f8H77k-xN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from gensim) (1.6.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 811 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting funcy\n",
      "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: joblib in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (1.0.1)\n",
      "Collecting numpy>=1.20.0\n",
      "  Downloading numpy-1.21.3-cp38-cp38-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Using cached future-0.18.2-py3-none-any.whl\n",
      "Requirement already satisfied: jinja2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (47.1.0)\n",
      "Requirement already satisfied: gensim in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (4.0.0)\n",
      "Requirement already satisfied: scipy in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (1.6.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (0.23.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (1.2.3)\n",
      "Requirement already satisfied: sklearn in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pyLDAvis) (0.0)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.7.3-cp38-cp38-macosx_10_9_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from pandas>=1.2.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn->pyLDAvis) (2.1.0)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136897 sha256=3dd9034cfc91834cf907d0080d1f54eae51ad2c79b97e94209c53c58f7fb5ba3\n",
      "  Stored in directory: /Users/TL/Library/Caches/pip/wheels/90/61/ec/9dbe9efc3acf9c4e37ba70fbbcc3f3a0ebd121060aa593181a\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: numpy, numexpr, future, funcy, pyLDAvis\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.3 which is incompatible.\u001b[0m\n",
      "Successfully installed funcy-1.16 future-0.18.2 numexpr-2.7.3 numpy-1.21.3 pyLDAvis-3.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run only if you do not have gensim and pyLDAvis on your device yet\n",
    "!pip install gensim\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "Rb8jAV6ck-xN",
   "metadata": {
    "id": "Rb8jAV6ck-xN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis, pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "r1RT6CaEk-xN",
   "metadata": {
    "id": "r1RT6CaEk-xN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-712ba0162128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a corpus from the documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_modified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get tokens from each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_texts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Create a GenSimdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_texts\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Create a GenSim corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a corpus from the documents\n",
    "texts = [[token for token in doc] for doc in df_modified['document']] # Get tokens from each document\n",
    "dictionary = Dictionary(split_texts) # Create a GenSimdictionary\n",
    "corpus = [dictionary.doc2bow(text) for text in split_texts] # Create a GenSim corpus\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "XAeeQmZEk-xN",
   "metadata": {
    "id": "XAeeQmZEk-xN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5910b973a8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create an LDA model with 3 topis from the generated corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m lda = LdaModel(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an LDA model with 3 topis from the generated corpus\n",
    "lda = LdaModel(\n",
    "    corpus=corpus, \n",
    "    id2word=dictionary, \n",
    "    num_topics=3\n",
    ")\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "zo_q3Upgk-xO",
   "metadata": {
    "id": "zo_q3Upgk-xO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b65c13c5ff80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the topic models and figure out the themes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the topic models and figure out the themes\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, corpus, dictionary)\n",
    "vis\n",
    "\n",
    "# Right-click the cell then choose \"Clear outputs\" when you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-punishment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-minority",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "06_nlp_context_aware.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
