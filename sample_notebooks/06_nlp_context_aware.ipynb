{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "BiKR78k2k-xF",
   "metadata": {
    "id": "BiKR78k2k-xF"
   },
   "source": [
    "# Natural Language Processing: Context-aware Tasks\n",
    "\n",
    "Hi everyone! Today, we're continuing with NLP, specifically looking at context-aware problems, features that we can extract at a document-level, and common context-aware tasks such as rules-based sentiment analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jAyu5SR9k-xG",
   "metadata": {
    "id": "jAyu5SR9k-xG"
   },
   "source": [
    "We will be extensively using SpaCy's `en_core_web_lg model` for many of the context-aware tasks today. This model was pre-trained on several corpuses such as OntoNotes 5, GloVe Common Crawl, and others ([source](https://spacy.io/models/en])). It comes with pipeline components such as a tokenizer, a POS tagger, a dependency parse, a lemmatizer, and an named entity recognizer. It also comes with pre-trained document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ERp2NAZzk-xG",
   "metadata": {
    "id": "ERp2NAZzk-xG"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spacy_pipeline.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8d9d8dbb0e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spacy_pipeline.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1225\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spacy_pipeline.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='spacy_pipeline.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-m0QOaJXk-xH",
   "metadata": {
    "id": "-m0QOaJXk-xH"
   },
   "source": [
    "By default, the SpaCy pipeline's preprocessing steps include tokenization, POS tagging, dependency parsing, and named entity recognition only. However, users have the option to use the other features such as lemmatization, embedding, and other self-defined steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dNLyvwxk-xH",
   "metadata": {
    "id": "4dNLyvwxk-xH"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run only if you do not have SpaCy and the en_core_web_lg model installed on your device yet\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-meditation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-48d60b3bdb5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxGLeCyxk-xH",
   "metadata": {
    "id": "sxGLeCyxk-xH"
   },
   "source": [
    "### Parts-of-speech (POS) tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "zMsfimrOk-xH",
   "metadata": {
    "id": "zMsfimrOk-xH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "BmAq17V-k-xI",
   "metadata": {
    "id": "BmAq17V-k-xI"
   },
   "outputs": [],
   "source": [
    "# Import spacy and the en_core_web_lg model\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "except:\n",
    "    print(\"Error loading 'en_core_web_lg' model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r0HPjvHgk-xI",
   "metadata": {
    "id": "r0HPjvHgk-xI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the en_core_web_lg_model to pre-process our text\n",
    "SpaCy's pre-trained model automatically determines various linguistic properties\n",
    "such as POS tags and dependency trees\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(\"The Philippine flight was delayed due to trouble with the airplane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "HyIvDdZqk-xI",
   "metadata": {
    "id": "HyIvDdZqk-xI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alphabet</th>\n",
       "      <th>is_stopword</th>\n",
       "      <th>head_text</th>\n",
       "      <th>head_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Philippine</td>\n",
       "      <td>philippine</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight</td>\n",
       "      <td>flight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>delayed</td>\n",
       "      <td>delay</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>due</td>\n",
       "      <td>due</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>due</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trouble</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>airplane</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>delayed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text       lemma    pos  tag dependency  shape is_alphabet  \\\n",
       "0          The         the    DET   DT        det    Xxx        True   \n",
       "1   Philippine  philippine    ADJ   JJ       amod  Xxxxx        True   \n",
       "2       flight      flight   NOUN   NN  nsubjpass   xxxx        True   \n",
       "3          was          be    AUX  VBD    auxpass    xxx        True   \n",
       "4      delayed       delay   VERB  VBN       ROOT   xxxx        True   \n",
       "5          due         due    ADP   IN       prep    xxx        True   \n",
       "6           to          to    ADP   IN      pcomp     xx        True   \n",
       "7      trouble     trouble   NOUN   NN       pobj   xxxx        True   \n",
       "8         with        with    ADP   IN       prep   xxxx        True   \n",
       "9          the         the    DET   DT        det    xxx        True   \n",
       "10    airplane    airplane   NOUN   NN       pobj   xxxx        True   \n",
       "11           .           .  PUNCT    .      punct      .       False   \n",
       "\n",
       "   is_stopword head_text head_pos  \n",
       "0         True    flight     NOUN  \n",
       "1        False    flight     NOUN  \n",
       "2        False   delayed     VERB  \n",
       "3         True   delayed     VERB  \n",
       "4        False   delayed     VERB  \n",
       "5         True   delayed     VERB  \n",
       "6         True       due      ADP  \n",
       "7        False        to      ADP  \n",
       "8         True   trouble     NOUN  \n",
       "9         True  airplane     NOUN  \n",
       "10       False      with      ADP  \n",
       "11       False   delayed     VERB  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize every \"token\" in the document\n",
    "tokens = pd.DataFrame(columns=\n",
    "                      ['text', 'lemma', 'pos', 'tag',\n",
    "                       'dependency', 'shape', 'is_alphabet',\n",
    "                       'is_stopword', 'head_text', 'head_pos'])\n",
    "\n",
    "for token in doc:\n",
    "    data = [token.text, token.lemma_, token.pos_,\n",
    "            token.tag_, token.dep_, token.shape_,\n",
    "            token.is_alpha, token.is_stop,\n",
    "            token.head.text, token.head.pos_]\n",
    "    tokens.loc[len(tokens)] = data\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6LEWLj9rk-xI",
   "metadata": {
    "id": "6LEWLj9rk-xI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"614e85ad9af141a6b7d391c71e45b88e-0\" class=\"displacy\" width=\"1975\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Philippine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">flight</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">delayed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">due</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">trouble</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">airplane.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-6\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,179.0 L1278.0,167.0 1262.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-7\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,179.0 L1453.0,167.0 1437.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-8\" stroke-width=\"2px\" d=\"M1645,177.0 C1645,89.5 1795.0,89.5 1795.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,179.0 L1637,167.0 1653,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-614e85ad9af141a6b7d391c71e45b88e-0-9\" stroke-width=\"2px\" d=\"M1470,177.0 C1470,2.0 1800.0,2.0 1800.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-614e85ad9af141a6b7d391c71e45b88e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,179.0 L1808.0,167.0 1792.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_bL36cIGk-xI",
   "metadata": {
    "id": "_bL36cIGk-xI"
   },
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "XG0ZpwCPk-xJ",
   "metadata": {
    "id": "XG0ZpwCPk-xJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the en_core_web_lg_model to pre-process our text\n",
    "SpaCy's pre-trained model also determines any named entities from text. \n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(\"The Philippine flight was delayed yesterday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "IP_JeOCdk-xJ",
   "metadata": {
    "id": "IP_JeOCdk-xJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Philippine, yesterday)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ktcZKj1k-xJ",
   "metadata": {
    "id": "3ktcZKj1k-xJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philippine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " flight was delayed \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WIY8arb1k-xJ",
   "metadata": {
    "id": "WIY8arb1k-xJ"
   },
   "source": [
    "### Rules-based sentiment analysis\n",
    "\n",
    "For sentiment analysis, we will be using the VADER model ([source](https://github.com/cjhutto/vaderSentiment)). VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. \n",
    "\n",
    "We will modify the SpaCy pipeline to add the additional step of using the VADER model to calculate the sentiment polarity of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "J30hyqNFk-xK",
   "metadata": {
    "id": "J30hyqNFk-xK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/TL/.pyenv/versions/3.8.5/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.12.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/TL/.pyenv/versions/3.8.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment and run only if you do not have VADER installed on your device yet\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cM0QeQHek-xK",
   "metadata": {
    "id": "cM0QeQHek-xK"
   },
   "outputs": [],
   "source": [
    "# Import VADER model\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Import Doc for extending the SpaCy pipeline\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "zLR_kKaLk-xK",
   "metadata": {
    "id": "zLR_kKaLk-xK"
   },
   "outputs": [],
   "source": [
    "# Define sentiment analysis extensions\n",
    "\"\"\"\n",
    "You can define the extension as a regular Python function:\n",
    "def sentiment_analysis(doc):\n",
    "    return sia.polarity_scores(doc.text)\n",
    "\"\"\"\n",
    "# Or you can create an anonymous lambda functions\n",
    "sentiment_analysis = lambda doc: sia.polarity_scores(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hb42zhi2k-xK",
   "metadata": {
    "id": "hb42zhi2k-xK"
   },
   "outputs": [],
   "source": [
    "# Instantiate NLP pipeline and set extensions\n",
    "nlp_with_sentiment = spacy.load(\"en_core_web_lg\")\n",
    "Doc.set_extension(\"sentiment\", getter=sentiment_analysis, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wL8_UDrxk-xK",
   "metadata": {
    "id": "wL8_UDrxk-xK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.708, 'pos': 0.292, 'compound': 0.4389}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp_with_sentiment(\"I love this school, but it's tiring sometimes!\")\n",
    "doc._.sentiment # Acccess custom properties using the \"._.\" operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JBKM44Aqk-xK",
   "metadata": {
    "id": "JBKM44Aqk-xK"
   },
   "source": [
    "### Process multiple documents\n",
    "\n",
    "SpaCy pipelines have an optimazation for processing multiple texts all at once using the `nlp.pipe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "jlwp4XCRk-xK",
   "metadata": {
    "id": "jlwp4XCRk-xK"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"I love this school, but it's tiring sometimes!\",\n",
    "        \"I'm looking forward to Christmas break.\",\n",
    "        \"I'm sad that midterms are over.\",\n",
    "        \"School is almost over.\",\n",
    "        \"I'll be relaxing during the Christmas break.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "regulated-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text\n",
       "0  I love this school, but it's tiring sometimes!\n",
       "1         I'm looking forward to Christmas break.\n",
       "2                 I'm sad that midterms are over.\n",
       "3                          School is almost over.\n",
       "4    I'll be relaxing during the Christmas break."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "GiL-lN4lk-xL",
   "metadata": {
    "id": "GiL-lN4lk-xL"
   },
   "outputs": [],
   "source": [
    "# Use the nlp.pipe() method to process a collection of texts\n",
    "docs = nlp_with_sentiment.pipe(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Opro5uXUk-xL",
   "metadata": {
    "id": "Opro5uXUk-xL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>com_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "      <td>(I, love, this, school, ,, but, it, 's, tiring...</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "      <td>(I, 'm, looking, forward, to, Christmas, break...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "      <td>(I, 'm, sad, that, midterms, are, over, .)</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "      <td>(School, is, almost, over, .)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "      <td>(I, 'll, be, relaxing, during, the, Christmas,...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  \\\n",
       "0  I love this school, but it's tiring sometimes!   \n",
       "1         I'm looking forward to Christmas break.   \n",
       "2                 I'm sad that midterms are over.   \n",
       "3                          School is almost over.   \n",
       "4    I'll be relaxing during the Christmas break.   \n",
       "\n",
       "                                            document  com_sent  pos_sent  \\\n",
       "0  (I, love, this, school, ,, but, it, 's, tiring...    0.4389     0.292   \n",
       "1  (I, 'm, looking, forward, to, Christmas, break...    0.0000     0.000   \n",
       "2         (I, 'm, sad, that, midterms, are, over, .)   -0.4767     0.000   \n",
       "3                      (School, is, almost, over, .)    0.0000     0.000   \n",
       "4  (I, 'll, be, relaxing, during, the, Christmas,...    0.4939     0.348   \n",
       "\n",
       "   neg_sent  neu_sent  \n",
       "0     0.000     0.708  \n",
       "1     0.000     1.000  \n",
       "2     0.383     0.617  \n",
       "3     0.000     1.000  \n",
       "4     0.000     0.652  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modified = pd.DataFrame(columns=['text', 'document', 'com_sent', 'pos_sent', 'neg_sent', 'neu_sent'])\n",
    "for doc in docs:\n",
    "    df_modified = df_modified.append(\n",
    "        {\n",
    "            'text': doc.text,\n",
    "            'document': doc,\n",
    "            'com_sent': doc._.sentiment['compound'],\n",
    "            'pos_sent': doc._.sentiment['pos'],\n",
    "            'neg_sent': doc._.sentiment['neg'],\n",
    "            'neu_sent': doc._.sentiment['neu']\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "brilliant-default",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>com_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>neg_sent</th>\n",
       "      <th>neu_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this school, but it's tiring sometimes!</td>\n",
       "      <td>(I, love, this, school, ,, but, it, 's, tiring...</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm looking forward to Christmas break.</td>\n",
       "      <td>(I, 'm, looking, forward, to, Christmas, break...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm sad that midterms are over.</td>\n",
       "      <td>(I, 'm, sad, that, midterms, are, over, .)</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>School is almost over.</td>\n",
       "      <td>(School, is, almost, over, .)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll be relaxing during the Christmas break.</td>\n",
       "      <td>(I, 'll, be, relaxing, during, the, Christmas,...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text  \\\n",
       "0  I love this school, but it's tiring sometimes!   \n",
       "1         I'm looking forward to Christmas break.   \n",
       "2                 I'm sad that midterms are over.   \n",
       "3                          School is almost over.   \n",
       "4    I'll be relaxing during the Christmas break.   \n",
       "\n",
       "                                            document  com_sent  pos_sent  \\\n",
       "0  (I, love, this, school, ,, but, it, 's, tiring...    0.4389     0.292   \n",
       "1  (I, 'm, looking, forward, to, Christmas, break...    0.0000     0.000   \n",
       "2         (I, 'm, sad, that, midterms, are, over, .)   -0.4767     0.000   \n",
       "3                      (School, is, almost, over, .)    0.0000     0.000   \n",
       "4  (I, 'll, be, relaxing, during, the, Christmas,...    0.4939     0.348   \n",
       "\n",
       "   neg_sent  neu_sent  \n",
       "0     0.000     0.708  \n",
       "1     0.000     1.000  \n",
       "2     0.383     0.617  \n",
       "3     0.000     1.000  \n",
       "4     0.000     0.652  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Er9ZOz9Mk-xL",
   "metadata": {
    "id": "Er9ZOz9Mk-xL"
   },
   "source": [
    "### Document embeddings\n",
    "\n",
    "SpaCy's `en_core_web_lg` model also comes with pre-trained document embeddings. As such, we can simply use them to immediately retrieve the embeddings of our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p6H0YZ5vk-xL",
   "metadata": {
    "id": "p6H0YZ5vk-xL"
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vlRud-2Xk-xL",
   "metadata": {
    "id": "vlRud-2Xk-xL"
   },
   "outputs": [],
   "source": [
    "doc.vector.shape # The embedding uses 300 feature columns only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qbCv9PK9k-xL",
   "metadata": {
    "id": "qbCv9PK9k-xL"
   },
   "outputs": [],
   "source": [
    "doc.vector # This is the embedding vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dk5tX8sAk-xM",
   "metadata": {
    "id": "dk5tX8sAk-xM"
   },
   "source": [
    "In the next following cells, we will attempt to embed a bunch of documents to retrieve their embedding vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NUW2g0dEk-xM",
   "metadata": {
    "id": "NUW2g0dEk-xM"
   },
   "outputs": [],
   "source": [
    "df_embedded = df.copy()\n",
    "df_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-cNhv_ovk-xM",
   "metadata": {
    "id": "-cNhv_ovk-xM"
   },
   "outputs": [],
   "source": [
    "# Embed a bunch of documents and append them to a dataframe\n",
    "documents = []\n",
    "vectors = []\n",
    "\n",
    "for doc in nlp.pipe(df['text']):\n",
    "    documents.append(doc)\n",
    "    vectors.append(doc.vector)\n",
    "    \n",
    "df_embedded['document'] = pd.Series(documents, name='document')\n",
    "df_embedded = df_embedded.join(pd.DataFrame(vectors))\n",
    "df_embedded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NO7G81Ark-xM",
   "metadata": {
    "id": "NO7G81Ark-xM"
   },
   "source": [
    "### Document similarity\n",
    "\n",
    "Now that we have document embeddings, we can use techniques such as cosine similarity to determine similarity between texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XX-yHDiJk-xM",
   "metadata": {
    "id": "XX-yHDiJk-xM"
   },
   "outputs": [],
   "source": [
    "a = nlp(\"Hello there!\")\n",
    "b = nlp(\"Greetings to you!\")\n",
    "c = nlp(\"Wikipedia is not a dictionary, or a usage or jargon guide.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lRvv3XvHk-xM",
   "metadata": {
    "id": "lRvv3XvHk-xM"
   },
   "outputs": [],
   "source": [
    "a.similarity(b) # The two sentences look very similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lGnxTlH0k-xN",
   "metadata": {
    "id": "lGnxTlH0k-xN"
   },
   "outputs": [],
   "source": [
    "a.similarity(c) # Not so similar (almost 50-50 coin toss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TSsCbYQdk-xN",
   "metadata": {
    "id": "TSsCbYQdk-xN"
   },
   "source": [
    "### Topic modeling and thematic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8GkeeE7Yk-xN",
   "metadata": {
    "id": "8GkeeE7Yk-xN"
   },
   "source": [
    "For topic modeling and thematic analysis, we will be using GenSim ([source](https://radimrehurek.com/gensim/)) and pyLDAvis ([source](https://github.com/bmabey/pyLDAvis)). We will use GenSim to implement the Latent-Dirichlet Allocation (LDA) model, and use pyLDAvis to visualize the results. \n",
    "\n",
    "WARNING: Your notebook might become buggy when using pyLDAvis. Once you are done looking at the visual, simply clear the output of the cell that uses the pyLDAvis chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pO1f8H77k-xN",
   "metadata": {
    "id": "pO1f8H77k-xN"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run only if you do not have gensim and pyLDAvis on your device yet\n",
    "!pip install gensim\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rb8jAV6ck-xN",
   "metadata": {
    "id": "Rb8jAV6ck-xN"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis, pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r1RT6CaEk-xN",
   "metadata": {
    "id": "r1RT6CaEk-xN"
   },
   "outputs": [],
   "source": [
    "# Create a corpus from the documents\n",
    "split_texts = [[token.text for token in doc] for doc in df_modified['document']] # Get tokens from each document\n",
    "\n",
    "# Split_texts: List[ List[str] ]\n",
    "dictionary = Dictionary(split_texts) # Create a GenSimdictionary\n",
    "corpus = [dictionary.doc2bow(text) for text in split_texts] # Create a GenSim corpus\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XAeeQmZEk-xN",
   "metadata": {
    "id": "XAeeQmZEk-xN"
   },
   "outputs": [],
   "source": [
    "# Create an LDA model with 3 topis from the generated corpus\n",
    "lda = LdaModel(\n",
    "    corpus=corpus, \n",
    "    id2word=dictionary, \n",
    "    num_topics=3\n",
    ")\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zo_q3Upgk-xO",
   "metadata": {
    "id": "zo_q3Upgk-xO"
   },
   "outputs": [],
   "source": [
    "# Visualize the topic models and figure out the themes\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, corpus, dictionary)\n",
    "vis\n",
    "\n",
    "# Right-click the cell then choose \"Clear outputs\" when you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-blocking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "06_nlp_context_aware.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
